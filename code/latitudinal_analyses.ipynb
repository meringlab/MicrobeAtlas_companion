{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767cc46a-65ba-46ab-9b89-a952725ed9a9",
   "metadata": {},
   "source": [
    "Note: all code is written in julia (https://julialang.org/) and should be compatible with julia v1.9 and later versions.\n",
    "\n",
    "Code author: Janko Tackmann (jtackm@github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6a2ce6-7c71-447e-a6d4-d53210a56fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Functions to compute and filter latitudinal associations #\n",
    "############################################################\n",
    "\n",
    "using MultipleTesting, SparseArrays, Statistics, FlashWeave, ProgressMeter\n",
    "\n",
    "function _populate_caches!(val_vec, group_vec, sum_cache, prev_cache)\n",
    "    for i in 1:length(val_vec)\n",
    "        group = group_vec[i]\n",
    "        sum_cache[group] += val_vec[i]\n",
    "        prev_cache[group] += 1\n",
    "    end\n",
    "\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function _populate_caches_logged!(val_vec::Union{SparseVector,SubArray{<:AbstractFloat, 1, <:SparseMatrixCSC}}, group_vec, sum_cache, \n",
    "    prev_cache, group_count_cache)\n",
    "    \"\"\"Optimized for (views of) sparse vectors\"\"\"\n",
    "    inds, vals = rowvals(val_vec), nonzeros(val_vec)\n",
    "\n",
    "    pcount = minimum(vals) / 10\n",
    "    \n",
    "    for (i, val) in zip(inds, vals)\n",
    "        group = group_vec[i]\n",
    "        sum_cache[group] += log10(val + pcount)\n",
    "        prev_cache[group] += 1\n",
    "    end\n",
    "\n",
    "    # Add pseudo-counts for zero entries by group\n",
    "    for i in 1:length(sum_cache)\n",
    "        # We know the number of zeros by subtracting the observed non-zeros (captured in prev_cache)\n",
    "        # from total group counts\n",
    "        n_zeros = group_count_cache[i] - prev_cache[i]\n",
    "        total_zero_pcounts_logged = log10(pcount) * n_zeros\n",
    "        sum_cache[i] += total_zero_pcounts_logged\n",
    "    end\n",
    "    \n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function _populate_caches!(val_vec::Union{SparseVector,SubArray{<:AbstractFloat, 1, <:SparseMatrixCSC}}, group_vec, sum_cache, \n",
    "    prev_cache)\n",
    "    \"\"\"Optimized for (views of) sparse vectors\"\"\"\n",
    "    inds, vals = rowvals(val_vec), nonzeros(val_vec)\n",
    "    \n",
    "    for (i, val) in zip(inds, vals)\n",
    "        group = group_vec[i]\n",
    "        sum_cache[group] += val\n",
    "        prev_cache[group] += 1\n",
    "    end\n",
    "    \n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function groupby_mean!(val_vec, group_vec, caches::NamedTuple; log_vals=false)\n",
    "    \"\"\"Assumes group_count_cache was pre-populated with counts per group\"\"\"\n",
    "    mean_cache, sum_cache, group_count_cache, prev_cache = caches.mean_cache, caches.sum_cache, caches.group_count_cache, caches.prev_cache\n",
    "    fill!(mean_cache, 0.0)\n",
    "    fill!(sum_cache, 0.0)\n",
    "    fill!(prev_cache, 0)\n",
    "\n",
    "    if log_vals\n",
    "        _populate_caches_logged!(val_vec, group_vec, sum_cache, prev_cache, group_count_cache)\n",
    "    else\n",
    "        _populate_caches!(val_vec, group_vec, sum_cache, prev_cache)\n",
    "    end\n",
    "\n",
    "    mean_cache .= sum_cache ./ group_count_cache\n",
    "    \n",
    "    return nothing\n",
    "end        \n",
    "\n",
    "function _fast_cor_binned(val_vec, v2_binned::Vector, bins_srt, caches::NamedTuple; log_means=false, log_vals=false)\n",
    "    \"\"\"Assumes values of v2_binned are equal to index range in caches. Otherwise, remap bins first to this range!\n",
    "    val_vec can be either a vector or a pair (col_i, data) in case of sparse matrices\"\"\"\n",
    "    @assert !(log_means && log_vals) \"'log_means' and 'log_vals' shouldn't be used together\"\n",
    "    \n",
    "    if all(iszero, val_vec)\n",
    "        stat = NaN\n",
    "        n_bins_obs = 0\n",
    "        prev = 0\n",
    "    else\n",
    "        groupby_mean!(val_vec, v2_binned, caches; log_vals)\n",
    "        n_bins_obs = sum(!iszero, caches.prev_cache)\n",
    "    \n",
    "        if log_means\n",
    "            pcount = if any(iszero.(caches.mean_cache))\n",
    "                minimum(caches.mean_cache[.!iszero.(caches.mean_cache)]) / 10\n",
    "            else\n",
    "                0.0\n",
    "            end\n",
    "            caches.mean_cache .= log10.(caches.mean_cache .+ pcount)\n",
    "        end\n",
    "        stat = cor(caches.mean_cache, bins_srt)\n",
    "        prev = sum(caches.prev_cache)\n",
    "    end\n",
    "    \n",
    "    return (;cor=stat, n_bins_obs, prev)\n",
    "end\n",
    "\n",
    "function compute_latitudinal_abundance_cors(otu_matn::KeyedArray, lats_binned::KeyedArray; prev_min=250, bins_obs_min_factor=-1, log_means=false, do_FDR=true, log_vals=false)\n",
    "    \"\"\"bins_obs_min_factor: factor defining the number of bins an OTU must have been observed in (e.g. factor 2 = observed in 50% of bins)\"\"\"\n",
    "    @assert axiskeys(otu_matn, 1) == axiskeys(lats_binned, 1)\n",
    "    @assert all(>=(0), lats_binned) \"all latitudes must be positive / absolute\"\n",
    "    n_samp = size(otu_matn, 1)\n",
    "    \n",
    "    # Map bins to monotonically increasing index range\n",
    "    bins_srt = sort(unique(lats_binned))\n",
    "    n_bins = length(bins_srt)\n",
    "\n",
    "    if bins_obs_min_factor != -1\n",
    "        n_bins_obs_min = div(n_bins, bins_obs_min_factor)\n",
    "    else\n",
    "        n_bins_obs_min = 0\n",
    "    end\n",
    "    \n",
    "    indmap = Dict(bin=>i for (i, bin) in enumerate(bins_srt))\n",
    "    lats_binned_indmap = [indmap[x] for x in Vector(lats_binned)]\n",
    "    caches = (abunds_cache=zeros(Float64, n_samp), mean_cache=zeros(Float64, n_bins), sum_cache=zeros(Float64, n_bins), group_count_cache=zeros(Int, n_bins), prev_cache=zeros(Int, n_bins))\n",
    "\n",
    "    # Populate per-bin sample counts\n",
    "    for bin_ind in lats_binned_indmap\n",
    "        caches.group_count_cache[bin_ind] += 1\n",
    "    end\n",
    "    \n",
    "    otu_mat = AxisKeys.keyless_unname(otu_matn)\n",
    "    cor_res = @showprogress map(enumerate(axiskeys(otu_matn, 2))) do (i, oid)\n",
    "        sub_cor_res = _fast_cor_binned(view(otu_mat, :, i), lats_binned_indmap, bins_srt, caches; log_means, log_vals)\n",
    "        (;oid, sub_cor_res..., n_obs=n_bins)\n",
    "    end\n",
    "\n",
    "    cor_df = DataFrame(cor_res)\n",
    "\n",
    "    # Remove unreliable OTUs (defined by filter criteria)\n",
    "    filt_mask = (cor_df.prev .< prev_min) .| (cor_df.n_bins_obs .< n_bins_obs_min)\n",
    "    rm_cor_df = cor_df[filt_mask, :]\n",
    "    cor_df = cor_df[.!filt_mask, :]\n",
    "\n",
    "    # Compute p-values for reliable OTUs\n",
    "    cor_df[!, :pval] = [FlashWeave.fz_pval(x.cor, x.n_obs, 0) for x in eachrow(cor_df)]\n",
    "\n",
    "    if do_FDR\n",
    "        cor_df[!, :pval_adj] = MultipleTesting.adjust(cor_df.pval, BenjaminiHochberg())\n",
    "    end\n",
    "\n",
    "    return (test_df=select(cor_df, :oid, :cor, r\"pval\", :n_obs, :prev, :n_bins_obs), unrel_df=rm_cor_df)\n",
    "end\n",
    "\n",
    "\"\"\"Bin elements in vector using standard Histogram parameters, return\n",
    "bin for each element (same order, lower bound)\n",
    "\"\"\"\n",
    "function make_bins(x::AbstractVector; n_bins=nothing, bin_kws...)\n",
    "    # assure interface compatibility with make_variable_bins\n",
    "    if !isnothing(n_bins) || haskey(bin_kws, :nbins)\n",
    "        if isnothing(n_bins)\n",
    "            n_bins = bin_kws[:nbins]\n",
    "        end\n",
    "        h = fit(Histogram, x; nbins=n_bins, bin_kws...)\n",
    "    else\n",
    "        h = fit(Histogram, x; bin_kws...)\n",
    "    end\n",
    "    hist_edges = h.edges[1]\n",
    "    return [hist_edges[findfirst(>(xi), hist_edges)-1] for xi in x]\n",
    "end\n",
    "\n",
    "function compute_latitudinal_abundance_cors_by_env(otu_matn_mp_lat, env_vec, lats_vec, n_bins, prev_min, bins_obs_min_factor,\n",
    "    log_vals, log_means)\n",
    "    dfs = []\n",
    "    unrel_dfs = []\n",
    "    \n",
    "    for env in unique(env_vec)\n",
    "        env == \"unknown\" && continue\n",
    "        println(env)\n",
    "        env_mask = env_vec .== env\n",
    "        lats_vec_mirr_env = lats_vec_mirr[env_mask]\n",
    "        otu_matn_mp_lat_env = otu_matn_mp_lat[findall(env_mask), :]\n",
    "        lats_binned_env = make_bins(lats_vec_mirr_env, n_bins=n_bins)\n",
    "        \n",
    "        # Remove OTUs whos prefered environment is not the current one\n",
    "        @assert axiskeys(pref_habs, 1) == axiskeys(otu_matn_mp_lat_env, 2)\n",
    "        oid_mask = findall(pref_habs .== env)\n",
    "        otu_matn_mp_lat_env = otu_matn_mp_lat_env[:, oid_mask]\n",
    "    \n",
    "        # Compute correlations\n",
    "        curr_cor_df, curr_unrel_df = compute_latitudinal_abundance_cors(otu_matn_mp_lat_env, lats_binned_env; prev_min, bins_obs_min_factor, log_vals, log_means, do_FDR=false)\n",
    "        curr_cor_df[!, :env] .= env\n",
    "        curr_unrel_df[!, :env] .= env\n",
    "        println(\"reliable / unreliable OTUs: \", nrow.([curr_cor_df, curr_unrel_df]))\n",
    "        println(\"significant OTUs (fraction):\")\n",
    "        sig_mask = curr_cor_df.pval .< 0.05\n",
    "        \n",
    "        for (desc, mask) in [(\"total\", trues(nrow(curr_cor_df))), (\"positive\", curr_cor_df.cor .> 0), (\"negative\", curr_cor_df.cor .< 0)]\n",
    "            println(\"\\t\", desc, \": \", sum(sig_mask[mask]), \" ($(mean(sig_mask .& mask)))\")\n",
    "        end\n",
    "        println()\n",
    "        \n",
    "        push!(dfs, curr_cor_df)\n",
    "        push!(unrel_dfs, curr_unrel_df)\n",
    "    end\n",
    "    \n",
    "    cor_df = vcat(dfs...)\n",
    "    \n",
    "    # Do final FDR\n",
    "    cor_df[!, :pval_adj] = MultipleTesting.adjust(cor_df.pval, BenjaminiHochberg())\n",
    "    cor_df[!, :is_sig] = cor_df.pval_adj .< 0.05\n",
    "    \n",
    "    unrel_df = vcat(unrel_dfs...)\n",
    "    \n",
    "    @show nrow.([cor_df, unrel_df])\n",
    "    \n",
    "    return cor_df\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
